{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1612737196755,
     "user": {
      "displayName": "Karol Kozłowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV9x2KrNfQZmjKpQG47J71mogdX4dtDGavKP8SAQ=s64",
      "userId": "02589226687852432598"
     },
     "user_tz": -60
    },
    "id": "ZvHtpnW6kpiJ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def read_data(path, limiter):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        path: path to dataset in jsonl file format\n",
    "        limiter: number of rows\n",
    "\n",
    "    Returns:\n",
    "        data: json dict, where every line is one sample as json\n",
    "    \"\"\"\n",
    "    with open(path) as file:\n",
    "        data = [json.loads(next(file)) for x in range(limiter)]\n",
    "    return data\n",
    "\n",
    "\n",
    "def transform_dll_imports(json_sample):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        json_sample: one sample of dataset\n",
    "\n",
    "    Returns:\n",
    "        functions_dict: dict with all dll functions name with value True\n",
    "    \"\"\"\n",
    "    imports = sample[\"imports\"]\n",
    "    functions_dict = {}\n",
    "    for key in imports.keys():\n",
    "        functions = imports[key]\n",
    "        functions_with_values = {key.lower() + \"-\" + f_name: True for f_name in functions}\n",
    "        functions_dict.update(functions_with_values)\n",
    "    return functions_dict\n",
    "\n",
    "\n",
    "def transform_dict(json_dict):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        json_dict: json dict with nested key-value, where value is list\n",
    "\n",
    "    Returns:\n",
    "        functions_dict: dict with value as a key and default value True\n",
    "    \"\"\"\n",
    "    result_dict = {}\n",
    "    for key in json_dict.keys():\n",
    "        keys = json_dict[key]\n",
    "        values_with_default = {key.lower() + \"-\" + f_name: True for f_name in keys}\n",
    "        result_dict.update(values_with_default)\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def transform_list(json_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        json_list: json list of values\n",
    "\n",
    "    Returns:\n",
    "        functions_dict: dict with all dll functions name with value True\n",
    "    \"\"\"\n",
    "    result_dict = {}\n",
    "    result_dict.update({i: True for i in json_list})\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def flatten_json(y, separator=''):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        y: json object\n",
    "        separator: separator\n",
    "\n",
    "    Returns:\n",
    "        functions_dict: dict with flatten values\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "\n",
    "    def flatten(x, name=separator):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                flatten(x[a], name + a + '_')\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                flatten(a, name + str(i) + '_')\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(y)\n",
    "    return out\n",
    "\n",
    "# Extract \"sha256\", \"md5\", \"appeared\", \"label\" and \"avclass\" columns to a flat form\n",
    "\n",
    "def get_simple_column(sample, columns = [\"sha256\", \"md5\", \"appeared\", \"label\", \"avclass\"]):\n",
    "    '''\n",
    "    input:\n",
    "        data: variable with dataset\n",
    "        columns: list of names extracted columns\n",
    "    output:\n",
    "        final_list: list of dicts, one list's element is a one sample of dataset\n",
    "    '''\n",
    "    simple_dict = {}\n",
    "    simple_dict.update({column:sample[column] for column in columns})\n",
    "    return simple_dict\n",
    "\n",
    "# Extraction columns with list: \"histogram\", \"byteentropy\", \"exports\"\n",
    "\n",
    "def get_simple_list_from_column(sample, columns = [\"histogram\", \"byteentropy\", \"exports\"]):\n",
    "\n",
    "    '''\n",
    "    input:\n",
    "        data: variable with dataset\n",
    "        columns: name of extracted columns (str)\n",
    "    output:\n",
    "        final_list: list of dicts, one list's element is a one sample of dataset\n",
    "    '''\n",
    "  \n",
    "    dict_exports = {}\n",
    "    dict_others = {}\n",
    "    dict_final = {}\n",
    "\n",
    "    for column in columns:\n",
    "        if column == \"exports\":\n",
    "            dict_exports.update({column+\"_\"+str(v).lower():True for v in sample[column]})\n",
    "        else:\n",
    "            dict_others.update({column+\"_\"+str(i):n for i, n in enumerate(sample[column])})             \n",
    "                \n",
    "    dict_final.update(dict_others)\n",
    "    dict_final.update(dict_exports)\n",
    "               \n",
    "    return dict_final\n",
    "\n",
    "\n",
    "# Extraction IMPORTS, GENERAL and STRINGS columns\n",
    "\n",
    "def get_features_from_dict_column(sample, columns = \"imports\"):\n",
    "    '''\n",
    "    input:\n",
    "            data\n",
    "            columns\n",
    "    output:\n",
    "            functions_with_valuex\n",
    "    '''\n",
    "    dict_final = {}\n",
    "    temp1 = {}\n",
    "    temp2 = {}\n",
    "    temp3 = {}\n",
    "\n",
    "    feature = sample[columns]\n",
    "    for key in feature.keys():\n",
    "        content = feature[key]\n",
    "        if (isinstance(content, list) and len(content)!=0):\n",
    "            if not isinstance(content[0], str):\n",
    "                temp1.update({columns +\"_\"+key.lower() + \"-\" + str(i):cont for i, cont in enumerate(content)})\n",
    "            else:\n",
    "                temp2.update({columns +\"_\"+ key.lower() + \"-\" + str(cont).lower():True for cont in content})\n",
    "        else:\n",
    "            temp3.update({columns+\"_\"+key:content})\n",
    "\n",
    "    dict_final.update(temp1)   \n",
    "    dict_final.update(temp2) \n",
    "    dict_final.update(temp3) \n",
    "    return dict_final\n",
    "\n",
    "# Extraction HEADER column\n",
    "\n",
    "def get_features_from_header(sample):\n",
    "    '''\n",
    "    input:\n",
    "        data: data\n",
    "    output:\n",
    "        list_final: list of dicts\n",
    "    '''    \n",
    "    headers = sample[\"header\"]\n",
    "    dict_lists = {}\n",
    "    dict_others = {}\n",
    "    dict_final = {}\n",
    "\n",
    "    for h in headers.keys():   \n",
    "        temp = headers[h]      \n",
    "        for k in temp.keys():  \n",
    "\n",
    "            if isinstance(temp[k], list):\n",
    "                dict_lists.update({\"header_\"+h.lower()+\"_\"+k.lower()+\"_\"+str(t).lower():True for t in temp[k]}) \n",
    "            else:\n",
    "                dict_others.update({\"header_\"+h.lower()+\"_\"+k.lower():temp[k]})\n",
    "\n",
    "    dict_final.update(dict_lists)    \n",
    "    dict_final.update(dict_others)\n",
    "    return dict_final\n",
    "\n",
    "\n",
    "# Extraction Section column\n",
    "\n",
    "def get_features_from_section(sample):\n",
    "\n",
    "    '''\n",
    "    input:\n",
    "        data: data\n",
    "    output:\n",
    "        list_final: list of dicts\n",
    "    '''  \n",
    "    section_entry = sample['section']['entry']    # .text\n",
    "    section_sections = sample['section']['sections']\n",
    "    dict_lists_sections = {}\n",
    "    dict_others_sections = {}\n",
    "    dict_final = {}\n",
    "\n",
    "    for part in section_sections:\n",
    "        name = part['name']\n",
    "        for position in ['size', 'entropy', 'vsize', 'props']:\n",
    "            if position == 'props':\n",
    "                dict_lists_sections.update({\"section_\"+section_entry.lower()+\"_sections\"+name.lower()+\"_\"+position+\"_\"+str(element).lower():True for element in part[position]})\n",
    "            else:\n",
    "                dict_others_sections.update({\"section_\"+section_entry.lower()+\"_sections\"+name.lower()+\"_\"+position:part[position]})\n",
    "    dict_final.update(dict_lists_sections)\n",
    "    dict_final.update(dict_others_sections)\n",
    "    return dict_final\n",
    "\n",
    "\n",
    "# Extraction DATADIRECTORIES column\n",
    "\n",
    "def get_features_from_datadirectories(sample):\n",
    "    '''\n",
    "    input:\n",
    "        data: data\n",
    "    output:\n",
    "        sum_others_datadir: list of dicts\n",
    "    '''  \n",
    "\n",
    "    dict_others_datadir = {}\n",
    "    datadir = sample[\"datadirectories\"]\n",
    "\n",
    "    for element in datadir:\n",
    "        element_name = element['name']\n",
    "        for position in ['size', 'virtual_address']:\n",
    "            dict_others_datadir.update({\"datadirectories_\"+element_name+\"_\"+position:element[position]})\n",
    "    return dict_others_datadir\n",
    "\n",
    "\n",
    "\n",
    "def write_csv(csv_file_path, sample_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        csv_file_path: destination path of csv file\n",
    "        sample_list: list of dicts \n",
    "    \"\"\"\n",
    "    all_keys = set().union(*(d.keys() for d in flatten_dataset))    \n",
    "\n",
    "    try:\n",
    "        with open(csv_file_path, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=all_keys)\n",
    "            writer.writeheader()\n",
    "            for data in flatten_dataset:\n",
    "                writer.writerow(data)\n",
    "    except IOError:\n",
    "        print(\"I/O error\")\n",
    "\n",
    "# 1. read datas\n",
    "data_path = 'C:/Users/zyche/Downloads/sample_data_6k.jsonl'\n",
    "data = read_data(data_path, limiter=1000)\n",
    "# 2. iterate over dataset\n",
    "flatten_dataset = []\n",
    "for sample in data:\n",
    "    # version 1 dummy way\n",
    "    # flat = flatten_json(sample)\n",
    "    # flatten_dataset.append(flat)\n",
    "    # collect transformed values for each sample\n",
    "\n",
    "    # version 2\n",
    "    transformed = {}\n",
    "\n",
    "    transformed.update(get_simple_column(sample))\n",
    "    transformed.update(get_simple_list_from_column(sample))\n",
    "    transformed.update(get_features_from_dict_column(sample, columns = \"strings\"))\n",
    "    transformed.update(get_features_from_dict_column(sample, columns = \"general\"))\n",
    "    transformed.update(get_features_from_dict_column(sample, columns = \"imports\"))\n",
    "    transformed.update(get_features_from_header(sample))\n",
    "    transformed.update(get_features_from_section(sample))\n",
    "    transformed.update(get_features_from_datadirectories(sample))\n",
    "\n",
    "\n",
    "    # here we fill with transform data\n",
    "    flatten_dataset.append(transformed)\n",
    "\n",
    "\n",
    "all_keys = set().union(*(d.keys() for d in flatten_dataset))    \n",
    "\n",
    "#save to csv file\n",
    "csv_file = \"flatten_sample_data_6k.csv\"\n",
    "write_csv(csv_file, flatten_dataset)    \n",
    "\n",
    "# read in chunks\n",
    "for chunk in pd.read_csv(csv_file, chunksize=10):\n",
    "    pass\n",
    "\n",
    "# change all transformed dataset to dataframe object\n",
    "df = pd.DataFrame(flatten_dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1612737198459,
     "user": {
      "displayName": "Karol Kozłowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV9x2KrNfQZmjKpQG47J71mogdX4dtDGavKP8SAQ=s64",
      "userId": "02589226687852432598"
     },
     "user_tz": -60
    },
    "id": "XFKtb0DylLiU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1612737198680,
     "user": {
      "displayName": "Karol Kozłowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV9x2KrNfQZmjKpQG47J71mogdX4dtDGavKP8SAQ=s64",
      "userId": "02589226687852432598"
     },
     "user_tz": -60
    },
    "id": "L0BNPmnmlLf0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 507,
     "status": "ok",
     "timestamp": 1612737199517,
     "user": {
      "displayName": "Karol Kozłowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV9x2KrNfQZmjKpQG47J71mogdX4dtDGavKP8SAQ=s64",
      "userId": "02589226687852432598"
     },
     "user_tz": -60
    },
    "id": "x52hh5AQlLdL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1612737200352,
     "user": {
      "displayName": "Karol Kozłowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV9x2KrNfQZmjKpQG47J71mogdX4dtDGavKP8SAQ=s64",
      "userId": "02589226687852432598"
     },
     "user_tz": -60
    },
    "id": "-AzZtsrGlLaj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 594,
     "status": "ok",
     "timestamp": 1612737200634,
     "user": {
      "displayName": "Karol Kozłowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV9x2KrNfQZmjKpQG47J71mogdX4dtDGavKP8SAQ=s64",
      "userId": "02589226687852432598"
     },
     "user_tz": -60
    },
    "id": "qOvIlnE8lLXs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 692,
     "status": "ok",
     "timestamp": 1612737200926,
     "user": {
      "displayName": "Karol Kozłowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV9x2KrNfQZmjKpQG47J71mogdX4dtDGavKP8SAQ=s64",
      "userId": "02589226687852432598"
     },
     "user_tz": -60
    },
    "id": "j6jP8dOUlWTW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1612737200927,
     "user": {
      "displayName": "Karol Kozłowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV9x2KrNfQZmjKpQG47J71mogdX4dtDGavKP8SAQ=s64",
      "userId": "02589226687852432598"
     },
     "user_tz": -60
    },
    "id": "6aq1QzgHlWQ7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1612737201140,
     "user": {
      "displayName": "Karol Kozłowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV9x2KrNfQZmjKpQG47J71mogdX4dtDGavKP8SAQ=s64",
      "userId": "02589226687852432598"
     },
     "user_tz": -60
    },
    "id": "JqgbJCsrlWOT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "executionInfo": {
     "elapsed": 713,
     "status": "ok",
     "timestamp": 1612737207827,
     "user": {
      "displayName": "Karol Kozłowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV9x2KrNfQZmjKpQG47J71mogdX4dtDGavKP8SAQ=s64",
      "userId": "02589226687852432598"
     },
     "user_tz": -60
    },
    "id": "sWcYAhiblAGn",
    "outputId": "f0f866bd-aeb0-4d34-82a8-7d771ebe2476"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha256</th>\n",
       "      <th>md5</th>\n",
       "      <th>appeared</th>\n",
       "      <th>label</th>\n",
       "      <th>avclass</th>\n",
       "      <th>histogram_0</th>\n",
       "      <th>histogram_1</th>\n",
       "      <th>histogram_2</th>\n",
       "      <th>histogram_3</th>\n",
       "      <th>histogram_4</th>\n",
       "      <th>...</th>\n",
       "      <th>imports_wintrust.dll-cryptcatadminreleasecatalogcontext</th>\n",
       "      <th>imports_wintrust.dll-wthelperprovdatafromstatedata</th>\n",
       "      <th>imports_wintrust.dll-winverifytrust</th>\n",
       "      <th>imports_wintrust.dll-wthelpergetprovsignerfromchain</th>\n",
       "      <th>imports_wintrust.dll-cryptcatadminreleasecontext</th>\n",
       "      <th>imports_ws2_32.dll-ordinal116</th>\n",
       "      <th>imports_ws2_32.dll-getaddrinfo</th>\n",
       "      <th>imports_ws2_32.dll-ordinal115</th>\n",
       "      <th>header_coff_characteristics_aggressive_ws_trim</th>\n",
       "      <th>header_optional_dll_characteristics_terminal_server_aware</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...</td>\n",
       "      <td>63956d6417f8f43357d9a8e79e52257e</td>\n",
       "      <td>2006-12</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>45521</td>\n",
       "      <td>13095</td>\n",
       "      <td>12167</td>\n",
       "      <td>12496</td>\n",
       "      <td>12429</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...</td>\n",
       "      <td>6f7bde7a1126debf0cc359a54953efc1</td>\n",
       "      <td>2007-01</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>93059</td>\n",
       "      <td>15789</td>\n",
       "      <td>2871</td>\n",
       "      <td>3005</td>\n",
       "      <td>4107</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1448 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sha256  \\\n",
       "0  0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...   \n",
       "1  c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...   \n",
       "\n",
       "                                md5 appeared  label avclass  histogram_0  \\\n",
       "0  63956d6417f8f43357d9a8e79e52257e  2006-12      0                45521   \n",
       "1  6f7bde7a1126debf0cc359a54953efc1  2007-01      0                93059   \n",
       "\n",
       "   histogram_1  histogram_2  histogram_3  histogram_4  ...  \\\n",
       "0        13095        12167        12496        12429  ...   \n",
       "1        15789         2871         3005         4107  ...   \n",
       "\n",
       "   imports_wintrust.dll-cryptcatadminreleasecatalogcontext  \\\n",
       "0                                                NaN         \n",
       "1                                               True         \n",
       "\n",
       "   imports_wintrust.dll-wthelperprovdatafromstatedata  \\\n",
       "0                                                NaN    \n",
       "1                                               True    \n",
       "\n",
       "   imports_wintrust.dll-winverifytrust  \\\n",
       "0                                  NaN   \n",
       "1                                 True   \n",
       "\n",
       "   imports_wintrust.dll-wthelpergetprovsignerfromchain  \\\n",
       "0                                                NaN     \n",
       "1                                               True     \n",
       "\n",
       "   imports_wintrust.dll-cryptcatadminreleasecontext  \\\n",
       "0                                               NaN   \n",
       "1                                              True   \n",
       "\n",
       "   imports_ws2_32.dll-ordinal116  imports_ws2_32.dll-getaddrinfo  \\\n",
       "0                            NaN                             NaN   \n",
       "1                           True                            True   \n",
       "\n",
       "   imports_ws2_32.dll-ordinal115  \\\n",
       "0                            NaN   \n",
       "1                           True   \n",
       "\n",
       "   header_coff_characteristics_aggressive_ws_trim  \\\n",
       "0                                             NaN   \n",
       "1                                            True   \n",
       "\n",
       "   header_optional_dll_characteristics_terminal_server_aware  \n",
       "0                                                NaN          \n",
       "1                                               True          \n",
       "\n",
       "[2 rows x 1448 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mT8KzPJ-nn-G"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPGYdmLfcgt9Xc2p6Xv/hjm",
   "collapsed_sections": [],
   "mount_file_id": "19npfCeNJNlmQUt7uoV8SA9BLK_SIq13R",
   "name": "Extracted Ember Dataset - final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
